<!DOCTYPE html>
<!--<script type="text/javascript" async="" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML"></script>-->
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="ReALFRED: An Embodied Instruction Following Benchmark in Photo-Realistic Environment">
  <meta name="keywords" content="Embodied AI">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>ReALFRED: An Embodied Instruction Following Benchmark in Photo-Realistic Environment</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-9BWYESK2L9"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-9BWYESK2L9');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://twoongg.github.io">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered is-full-width">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title" style="font-size:45px">
            ReALFRED: An Embodied Instruction Following  <br>
            Benchmark in Photo-Realistic Environments
          </h1>
          <h1 class="title is-4 publication-title">
            ECCV 2024
          </h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://twoongg.github.io">Taewoong Kim</a><sup>1,*</sup>,
            </span>
            <span class="author-block">
              <a href="https://mch0916.github.io">Cheolhong Min</a><sup>1,*</sup>,
            </span>
            <span class="author-block">
              <a href="https://bhkim94.github.io">Byeonghwi Kim</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://wild-reptile-5c4.notion.site/Jinyeon-Kim-s-Portfolio-page-ef855010f6c445488ad6969ed7cda11f?pvs=4">Jinyeon Kim</a><sup>1,2</sup>,
            </span>
            <span class="author-block">
              <a href="https://cryinginitial.github.io/">Wonje Jeung</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://ppolon.github.io">Jonghyun Choi</a><sup>1,&dagger;</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <sup>1</sup><span class="author-block">Seoul National University</span>
            <sup>2</sup><span class="author-block">Yonsei University</span>
            <br>
            <p style="font-size:17px"><sup>*</sup>Equal Contribution.<sup>&dagger;</sup>Corresponding author.</p>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://TBD"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper (coming soon)</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://TBD"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv  (coming soon)</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/snumprlab/realfred"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/datasets/SNUMPR/realfred_json" 
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data 1</span>
                  </a>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/datasets/SNUMPR/realfred_feat" 
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data 2</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src='static/figures/teaser.png' style="margin-left: auto; margin-right: auto; display: block; border-style: none width:100%;max-width:100%">
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Proposed ReALFRED bechmark</span>
      </h2>
    </div>
  </div>
</section>



<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Simulated virtual environments have been widely used to learn robotic agents that perform daily household tasks. These environments encourage research progress by far, but often provide limited object interactability, visual appearance different from real-world environments, or relatively smaller environment sizes. This prevents the learned models in the virtual scenes from being readily deployable. To bridge the gap between these learning environments and deploying (i.e., real) environments, we propose the ReALFRED benchmark that employs real-world scenes, objects, and room layouts to learn agents to complete household tasks by understanding free-form language instructions and interacting with objects in large, multi-room and 3D-captured scenes. Specifically, we extend the ALFRED benchmark with updates for larger environmental spaces with smaller visual domain gaps. With ReALFRED, we analyze previously crafted methods for the ALFRED benchmark and observe that they consistently yield lower performance in all metrics, encouraging the community to develop methods in more realistic environments. Our code and data are publicly available.
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-widescreen">
    <h2 class="title is-3">The ReALFRED Benchmark</h2>

    <div class="content has-text-justified">
      <p>
        To develop agents capable of performing household tasks, substantial progress
        has been achieved in various domains, including navigation, rearrangement, and manipulation tasks. In particular, Shridhar <i>et al.</i> recently introduced
        the <span style="color: #305fac"><a href="https://askforalfred.com/">ALFRED</a></span> benchmark that requires agents to complete long-horizon household tasks by jointly understanding egocentric visual observations and natural
        language instructions in household environments.
      </p>
      <p>
        However, the spatial size of these environments is somewhat restricted to a
        single room compared to the size of previously proposed 3D-captured environments consisting of multiple rooms, which could potentially restrict the
        deployability of agents to larger environments. Furthermore, the environments
        used in the ALFRED benchmark are built with synthetic CAD assets and
        therefore could potentially yield visual aesthetics different from those obtained
        from real-world environments, which could eventually cause performance
        degradation due to visual domain gaps.
        </p>
        <p>
        To address these issues, we extend the ALFRED benchmark and propose
        a challenging benchmark, named the <b>ReALFRED</b> benchmark, which requires
        agents to perform household tasks in large indoor environments captured in 3D
        with object interaction. For training and evaluation, we follow the same protocol
        as ALFRED to collect expert demonstrations in the captured large environments.
      </p>
      
    </div>

    <div class="columns is-centered">
      <div class="column is-two-quarters">
        <div class="columns is-centered has-text-centered">
          <div class="column is-two-quarters">
            <img src="static/figures/image.png">
            <h5>While other benchmarks provide one or two aspects, our
              proposed <b>ReALFRED</b> benchmark addresses all of these aspects.</h5>
            <h5>1. Photo-realistic, 2. Interaction, and 3. Free-from language</h5>
          </div>
        </div>
      </div>
      <div class="column is-two-quarters">
        <div class="columns is-centered has-text-centered">
          <div class="column is-two-quarters">
            <img src="static/figures/word-distribution.png">
            <h5>Word distribution</h5>
            <h5> The ReALFRED benchmark
              offers 30,696 language directives, each
              comprising a human-annotated high-level
              goal and a set of step-by-step instructions. These directives are collected from
              93 Amazon Mechanical Turk workers with
              a Master qualification, ensuring highquality. Collected annotations are validated through an additional voting survey, and invalid instructions are replaced
              with newly collected instructions.</h5>
          </div>
        </div>
      </div>
    </div>

</section>


<section class="section">
  <div class="container is-max-widescreen">
    <h2 class="title is-3">Visualization</h2>
    <p>Will be available soon!</p>
</section>

<section class="hero is-light">
  <div class="hero-body">
    <div class="container is-max-widescreen">
      <h2 class="title is-3">Results</h2>
      <div class="content has-text-justified">
        <p>
          We follow the same evaluation protocol of the <span style="color: #305fac"><a href="https://askforalfred.com/">ALFRED</a></span> benchmark.
          The primary metric is Success Rate (SR) which measures the percentage of
          completed tasks. Goal-Condition Success Rate (GC) measures the percentage
          of achieved goal conditions. Finally, we also measure the penalized SR and GC
          by the length of the trajectory path (<i>i.e.</i>, PLWSR and PLWGC) which indicate
          how efficiently an agent completes tasks. 
        <p>
        <p>
          For more details, please check out the paper.
        </p>
        <br>
        <div class="columns is-centered has-text-centered">
          <div class="column is-full-width">
            <img src="static/tables/results.png">
            <h5>Task and Goal-Condition Success Rate</h5>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{kim2024realfred,
  author    = {Kim, Taewoong and Min, Cheolhong and Kim, Byeonghwi and Kim, Jinyeon and Jeung, Wonje and Choi, Jonghyun},
  title     = {ReALFRED: An Embodied Instruction Following Benchmark in Photo-Realistic Environment},
  booktitle = {ECCV},
  year      = {2024},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          The website template is from <a href="https://github.com/nerfies/nerfies.github.io">here</a>.
        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Default Statcounter code for realfred
https://twoongg.github.io/projects/realfred/ -->
<script type="text/javascript">
var sc_project=13014131; 
var sc_invisible=1; 
var sc_security="6db63f9f"; 
</script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js" async></script>
<noscript><div class="statcounter"><a title="Web Analytics Made Easy -
Statcounter" href="https://statcounter.com/" target="_blank"><img
class="statcounter" src="https://c.statcounter.com/13014131/0/6db63f9f/1/"
alt="Web Analytics Made Easy - Statcounter"
referrerPolicy="no-referrer-when-downgrade"></a></div></noscript>
<!-- End of Statcounter Code -->
</body>
</html>
